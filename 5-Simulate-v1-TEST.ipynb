{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version :  3.6.8 (default, Oct  7 2019, 12:59:55) \n",
      "[GCC 8.3.0]\n",
      "TensorFlow version :  1.15.0\n",
      "Keras version :  2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import config as cfg\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "print('Python version : ', sys.version)\n",
    "print('TensorFlow version : ', tf.__version__)\n",
    "print('Keras version : ', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38483\n",
      "38483\n",
      "\n",
      "(38483, 66, 100, 1)\n",
      "(38483, 6)\n",
      "\n",
      "(66, 100, 1)\n",
      "(66, 100, 1)\n",
      "data load ... done\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "num_classes = cfg.NUM_KEYS\n",
    "\n",
    "#read data.csv\n",
    "increased_path = '../dataset/20200512/3-increased'\n",
    "with open(increased_path + '/data.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        # print(row[0], row[1])\n",
    "        xs.append(increased_path + '/' + row[0])\n",
    "        ys.append(int(row[1]))\n",
    "\n",
    "        \n",
    "increased_path = '../dataset/20200513/3-increased'\n",
    "with open(increased_path + '/data.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        # print(row[0], row[1])\n",
    "        xs.append(increased_path + '/' + row[0])\n",
    "        ys.append(int(row[1]))\n",
    "        \n",
    "#read data.csv\n",
    "increased_path = '../dataset/training-data-shortcut/3-increased'\n",
    "with open(increased_path + '/data.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        # print(row[0], row[1])\n",
    "        xs.append(increased_path + '/' + row[0])\n",
    "        ys.append(int(row[1]))\n",
    "\n",
    "        \n",
    "increased_path = '../dataset/training-data-stop/3-increased'\n",
    "with open(increased_path + '/data.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        # print(row[0], row[1])\n",
    "        xs.append(increased_path + '/' + row[0])\n",
    "        ys.append(int(row[1]))\n",
    "\n",
    "\n",
    "# 파일명을 이용해서 실제 이미지 불러오기\n",
    "num_images = len(xs)\n",
    "assert len(xs) == len(ys)\n",
    "x_images = []\n",
    "y_labels = []\n",
    "\n",
    "for i in range(num_images):\n",
    "    filepath = xs[i]\n",
    "    colorIMG = cv2.imread(filepath)[cfg.modelheight:]\n",
    "    grayIMG = cv2.cvtColor(colorIMG, cv2.COLOR_BGR2GRAY)\n",
    "    x_images.append(cv2.resize(grayIMG, dsize=(cfg.final_width, cfg.final_height)) / 255.0)\n",
    "    y_labels.append([ys[i]])\n",
    "\n",
    "#x_test_images = tf.reshape(x_test_images, [len(x_test_images), cfg.final_height, cfg.final_width, 1])\n",
    "x_images = np.array(x_images)\n",
    "x_images.reshape(x_images.shape[0], cfg.final_height, cfg.final_width, 1)\n",
    "x_images = np.expand_dims(x_images, axis=-1)\n",
    "\n",
    "y_labels = keras.utils.to_categorical(y_labels, num_classes)\n",
    "\n",
    "\n",
    "print(len(x_images))  # 전체 데이터 수\n",
    "print(len(y_labels))  # 전체 데이터 수\n",
    "print()\n",
    "\n",
    "print(x_images.shape)\n",
    "print(y_labels.shape)\n",
    "print()\n",
    "\n",
    "print(x_images[0].shape)  # 학습용 이미지 한개의 차원\n",
    "print(x_images[0].shape)  # 학습용 레이블 한개의 차원\n",
    "\n",
    "print('data load ... done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "model ... loaded\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(0)\n",
    "\n",
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "new_model = tf.keras.models.load_model('save/my_model.h5')\n",
    "print('model ... loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 66, 100, 32)       832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 33, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 33, 50, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              25601000  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 6006      \n",
      "=================================================================\n",
      "Total params: 25,616,094\n",
      "Trainable params: 25,616,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9898397\n"
     ]
    }
   ],
   "source": [
    "score = new_model.evaluate(x_images, y_labels, verbose=0)\n",
    "#print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "확인한 사진 수 : 1000 | 정확도:  97.7\n",
      "확인한 사진 수 : 2000 | 정확도:  98.2\n",
      "확인한 사진 수 : 3000 | 정확도:  98.2\n",
      "확인한 사진 수 : 4000 | 정확도:  98.25\n",
      "확인한 사진 수 : 5000 | 정확도:  98.22\n",
      "확인한 사진 수 : 6000 | 정확도:  97.92\n",
      "확인한 사진 수 : 7000 | 정확도:  97.89\n",
      "확인한 사진 수 : 8000 | 정확도:  98.11\n",
      "확인한 사진 수 : 9000 | 정확도:  98.21\n",
      "확인한 사진 수 : 10000 | 정확도:  98.31\n",
      "확인한 사진 수 : 11000 | 정확도:  98.41\n",
      "확인한 사진 수 : 12000 | 정확도:  98.52\n",
      "확인한 사진 수 : 13000 | 정확도:  98.59\n",
      "확인한 사진 수 : 14000 | 정확도:  98.65\n",
      "확인한 사진 수 : 15000 | 정확도:  98.67\n",
      "확인한 사진 수 : 16000 | 정확도:  98.74\n",
      "확인한 사진 수 : 17000 | 정확도:  98.8\n",
      "확인한 사진 수 : 18000 | 정확도:  98.81\n",
      "확인한 사진 수 : 19000 | 정확도:  98.72\n",
      "확인한 사진 수 : 20000 | 정확도:  98.67\n",
      "확인한 사진 수 : 21000 | 정확도:  98.58\n",
      "확인한 사진 수 : 22000 | 정확도:  98.59\n",
      "확인한 사진 수 : 23000 | 정확도:  98.61\n",
      "확인한 사진 수 : 24000 | 정확도:  98.6\n",
      "확인한 사진 수 : 25000 | 정확도:  98.65\n",
      "확인한 사진 수 : 26000 | 정확도:  98.63\n",
      "확인한 사진 수 : 27000 | 정확도:  98.63\n",
      "확인한 사진 수 : 28000 | 정확도:  98.67\n",
      "확인한 사진 수 : 29000 | 정확도:  98.68\n",
      "확인한 사진 수 : 30000 | 정확도:  98.72\n",
      "확인한 사진 수 : 31000 | 정확도:  98.74\n",
      "확인한 사진 수 : 32000 | 정확도:  98.78\n",
      "확인한 사진 수 : 33000 | 정확도:  98.82\n",
      "확인한 사진 수 : 34000 | 정확도:  98.85\n",
      "확인한 사진 수 : 35000 | 정확도:  98.89\n",
      "확인한 사진 수 : 36000 | 정확도:  98.92\n",
      "확인한 사진 수 : 37000 | 정확도:  98.95\n",
      "확인한 사진 수 : 38000 | 정확도:  98.97\n",
      "전체 이미지 수 38483\n",
      "LEFT 를 못맞춘 경우의 수: 38\n",
      "RIGHT 를 못맞춘 경우의 수: 18\n",
      "FORWARD 를 못맞춘 경우의 수: 165\n",
      "FORWARD-LEFT 를 못맞춘 경우의 수: 43\n",
      "FORWARD-RIGHT 를 못맞춘 경우의 수: 127\n",
      "ETC 를 못맞춘 경우의 수: 0\n"
     ]
    }
   ],
   "source": [
    "correct_num = 0\n",
    "missed_forward = 0\n",
    "missed_left = 0\n",
    "missed_right = 0\n",
    "missed_upleft = 0\n",
    "missed_upright = 0\n",
    "missed_etc = 0\n",
    "\n",
    "for i in range(num_images):\n",
    "    filepath = xs[i]\n",
    "    full_image = cv2.imread(filepath)\n",
    "    full_image_gray = cv2.cvtColor(full_image, cv2.COLOR_BGR2GRAY)\n",
    "    image_feed2model = cv2.resize(full_image_gray[cfg.modelheight:], dsize=(cfg.final_width, cfg.final_height)) / 255.0\n",
    "    image_feed2model = np.array(image_feed2model)\n",
    "    image_feed2model = np.expand_dims(image_feed2model, axis=-1)\n",
    "    image_feed2model = np.expand_dims(image_feed2model, axis=0)\n",
    "    \n",
    "    #new_model.evaluate(image_feed2model)\n",
    "    ret = new_model.predict(image_feed2model, batch_size=1)\n",
    "    #print(ret)\n",
    "    wheel = np.argmax(ret)\n",
    "    #print(wheel)\n",
    "    \n",
    "    if int(ys[i]) == wheel:\n",
    "        correct_num += 1\n",
    "    else:\n",
    "        if int(ys[i]) == cfg.LEFT:  # LEFT\n",
    "            missed_left += 1\n",
    "        elif int(ys[i]) == cfg.UP:  # FORWARD\n",
    "            missed_forward += 1\n",
    "        elif int(ys[i]) == cfg.RIGHT:  # RIGHT\n",
    "            missed_right += 1\n",
    "        elif int(ys[i]) == cfg.UP_LEFT:\n",
    "            missed_upleft += 1\n",
    "        elif int(ys[i]) == cfg.UP_RIGHT:\n",
    "            missed_upright += 1\n",
    "        else:  # etc\n",
    "            missed_etc = missed_etc + 1\n",
    "            \n",
    "    if (i > 0) and (i % 1000 == 0):\n",
    "        print('확인한 사진 수 :', i, '| 정확도: ', round((correct_num/i)*100, 2))\n",
    "            \n",
    "# summary\n",
    "print('전체 이미지 수 ' + str(len(xs)))\n",
    "print('LEFT 를 못맞춘 경우의 수: ' + str(missed_left))\n",
    "print('RIGHT 를 못맞춘 경우의 수: ' + str(missed_right))\n",
    "print('FORWARD 를 못맞춘 경우의 수: ' + str(missed_forward))\n",
    "print('FORWARD-LEFT 를 못맞춘 경우의 수: ' + str(missed_upright))\n",
    "print('FORWARD-RIGHT 를 못맞춘 경우의 수: ' + str(missed_upleft))\n",
    "print('ETC 를 못맞춘 경우의 수: ' + str(missed_etc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
